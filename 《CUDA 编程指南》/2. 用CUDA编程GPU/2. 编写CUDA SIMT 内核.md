CUDA C++内核在很大程度上可以按照传统CPU代码解决特定问题的方式来编写。不过，GPU有一些独特的特性可以用来提升性能。此外，了解GPU上的线程是如何调度的、它们如何访问内存以及它们的执行过程，有助于开发人员编写能最大限度利用可用计算资源的内核。

## 1. SIMT 基础

从开发者的角度来看，CUDA线程是并行的基本单位。[线程束与SIMT]()描述了GPU执行的基本SIMT模型，[SIMT执行模型]()提供了SIMT模型的更多细节。

SIMT模型允许每个线程维护自己的状态和控制流。从功能角度而言，每个线程可以执行独立的代码路径。不过，通过确保内核代码尽可能减少同一线程束中的线程出现代码路径分歧的情况，能够显著提升性能。

## 2. 线程层次结构

线程被组织成线程块，线程块再被组织成网格。网格可以是一维、二维或三维的，在核函数内部可以通过内置变量```gridDim```查询网格的大小。

线程块也可以是一维、二维或三维的。在核函数内部可以通过内置变量```blockDim```查询线程块的大小。可以通过内置变量```blockIdx```查询线程块的索引。在线程块内，可以使用内置变量```threadIdx```获取线程的索引。

这些内置变量用于为每个线程计算唯一的全局线程索引，从而使每个线程能够从全局内存中加载/存储特定数据，并根据需要执行独特的代码路径。

+ ```gridDim.[x|y|z]```：分别为x、y和z维度上的网格大小。这些值在核函数启动时设置。

+ ```blockDim.[x|y|z]```：分别为块在x、y和z维度上的大小。这些值在核函数启动时设置

+ ```blockIdx.[x|y|z]```：分别是块在x、y和z维度上的索引。这些值会根据正在执行的块而变化。

+ ```threadIdx.[x|y|z]```：线程在x、y和z维度上的索引，分别对应这三个维度。这些值会根据正在执行的线程而变化。

使用多维线程块和网格仅为方便起见，并不影响性能。一个块的线程会以可预测的方式线性化：第一个索引```x```变化最快，其次是```y```，然后是```z```。

这意味着在线程索引的线性化过程中，```threadIdx.x```的连续值表示连续的线程，```threadIdx.y```的步长为```blockDim.x```，```threadIdx.z```的步长为```blockDim.x * blockDim.y```。这会影响线程如何分配给线程束，详情见硬件多线程。

下图展示了一个带有一维线程块的二维网格的简单示例

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/grid-of-thread-blocks.png)

线程块网格

## 3. GPU设备内存空间

CUDA设备有多个内存空间，可由内核中的CUDA线程访问。下表总结了常见的内存类型、它们的线程范围以及生命周期。以下各节将更详细地解释这些内存类型中的每一种。

| 内存类型 | 作用域 | 生存期 | 位置 |
|---------|--------|-------|--------|
| 全局 | 网格 | 应用程序 | 设备 |
| 常量 | 网格 | 应用程序 | 设备 |
| 共享 | 块 | 内核 | SM |
| 局部 | 线程 | 内核 | 设备 |
| 注册 | 线程 | 内核 | SM |

### 3.1. 全局内存

全局内存（也称为设备内存）是用于存储可由内核中所有线程访问的数据的主要内存空间。它类似于CPU系统中的RAM。在GPU上运行的内核可以直接访问全局内存，就像在CPU上运行的代码可以访问系统内存一样。

全局内存是持久的。也就是说，在全局内存中进行的分配及其存储的数据会一直存在，直到该分配被释放或应用程序终止。```cudaDeviceReset``` 也会释放所有分配。

全局内存通过诸如```cudaMalloc```和```cudaMallocManaged```之类的CUDA API调用进行分配。可以使用```cudaMemcpy```等CUDA运行时API调用将数据从CPU内存复制到全局内存。通过CUDA API进行的全局内存分配可使用```cudaFree```释放。

在启动内核之前，全局内存通过CUDA API调用进行分配和初始化。在内核执行期间，CUDA线程可以读取全局内存中的数据，并且CUDA线程执行操作得到的结果可以写回全局内存。一旦内核完成执行，它写入全局内存的结果可以复制回主机，或者被GPU上的其他内核使用。

由于全局内存可被网格中的所有线程访问，因此必须注意避免线程之间的数据竞争。由于从主机启动的CUDA内核具有void返回类型，内核计算出的数值结果返回给主机的唯一方式是将这些结果写入全局内存。

一个说明全局内存使用的简单示例是下面的```vecAdd```内核，其中三个数组```A```、```B```和```C````位于全局内存中，并由这个向量加法内核进行访问。

```c++
__global__ void vecAdd(float* A, float* B, float* C, int vectorLength)
{
    int workIndex = threadIdx.x + blockIdx.x*blockDim.x;
    if(workIndex < vectorLength)
    {
        C[workIndex] = A[workIndex] + B[workIndex];
```

### 3.2. 共享内存

共享内存是线程块中所有线程都可访问的内存空间。它物理上位于每个SM上，并与L1缓存（统一数据缓存）使用相同的物理资源。共享内存中的数据在整个内核执行期间保持不变。共享内存可视为内核执行期间使用的用户管理的暂存器。
虽然与全局内存相比容量较小，但由于共享内存位于每个SM上，因此其带宽比访问全局内存更高，延迟更低。

由于共享内存可被线程块中的所有线程访问，因此必须注意避免同一线程块中线程之间的数据竞争。可以使用```__syncthreads()```函数实现同一线程块中线程之间的同步。此函数会阻塞线程块中的所有线程，直到所有线程都执行到对```__syncthreads()```的调用。
