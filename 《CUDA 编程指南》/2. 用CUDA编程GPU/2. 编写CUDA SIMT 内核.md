CUDA C++内核在很大程度上可以按照传统CPU代码解决特定问题的方式来编写。不过，GPU有一些独特的特性可以用来提升性能。此外，了解GPU上的线程是如何调度的、它们如何访问内存以及它们的执行过程，有助于开发人员编写能最大限度利用可用计算资源的内核。

## 1. SIMT 基础

从开发者的角度来看，CUDA线程是并行的基本单位。[线程束与SIMT]()描述了GPU执行的基本SIMT模型，[SIMT执行模型]()提供了SIMT模型的更多细节。

SIMT模型允许每个线程维护自己的状态和控制流。从功能角度而言，每个线程可以执行独立的代码路径。不过，通过确保内核代码尽可能减少同一线程束中的线程出现代码路径分歧的情况，能够显著提升性能。

## 2. 线程层次结构

线程被组织成线程块，线程块再被组织成网格。网格可以是一维、二维或三维的，在核函数内部可以通过内置变量```gridDim```查询网格的大小。

线程块也可以是一维、二维或三维的。在核函数内部可以通过内置变量```blockDim```查询线程块的大小。可以通过内置变量```blockIdx```查询线程块的索引。在线程块内，可以使用内置变量```threadIdx```获取线程的索引。

这些内置变量用于为每个线程计算唯一的全局线程索引，从而使每个线程能够从全局内存中加载/存储特定数据，并根据需要执行独特的代码路径。

+ ```gridDim.[x|y|z]```：分别为x、y和z维度上的网格大小。这些值在核函数启动时设置。

+ ```blockDim.[x|y|z]```：分别为块在x、y和z维度上的大小。这些值在核函数启动时设置

+ ```blockIdx.[x|y|z]```：分别是块在x、y和z维度上的索引。这些值会根据正在执行的块而变化。

+ ```threadIdx.[x|y|z]```：线程在x、y和z维度上的索引，分别对应这三个维度。这些值会根据正在执行的线程而变化。

使用多维线程块和网格仅为方便起见，并不影响性能。一个块的线程会以可预测的方式线性化：第一个索引```x```变化最快，其次是```y```，然后是```z```。

这意味着在线程索引的线性化过程中，```threadIdx.x```的连续值表示连续的线程，```threadIdx.y```的步长为```blockDim.x```，```threadIdx.z```的步长为```blockDim.x * blockDim.y```。这会影响线程如何分配给线程束，详情见硬件多线程。

下图展示了一个带有一维线程块的二维网格的简单示例

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/grid-of-thread-blocks.png)

线程块网格

## 3. GPU设备内存空间

CUDA设备有多个内存空间，可由内核中的CUDA线程访问。下表总结了常见的内存类型、它们的线程范围以及生命周期。以下各节将更详细地解释这些内存类型中的每一种。

| 内存类型 | 作用域 | 生存期 | 位置 |
|---------|--------|-------|--------|
| 全局 | 网格 | 应用程序 | 设备 |
| 常量 | 网格 | 应用程序 | 设备 |
| 共享 | 块 | 内核 | SM |
| 局部 | 线程 | 内核 | 设备 |
| 注册 | 线程 | 内核 | SM |

### 3.1. 全局内存

全局内存（也称为设备内存）是用于存储可由内核中所有线程访问的数据的主要内存空间。它类似于CPU系统中的RAM。在GPU上运行的内核可以直接访问全局内存，就像在CPU上运行的代码可以访问系统内存一样。

全局内存是持久的。也就是说，在全局内存中进行的分配及其存储的数据会一直存在，直到该分配被释放或应用程序终止。```cudaDeviceReset``` 也会释放所有分配。

全局内存通过诸如```cudaMalloc```和```cudaMallocManaged```之类的CUDA API调用进行分配。可以使用```cudaMemcpy```等CUDA运行时API调用将数据从CPU内存复制到全局内存。通过CUDA API进行的全局内存分配可使用```cudaFree```释放。

在启动内核之前，全局内存通过CUDA API调用进行分配和初始化。在内核执行期间，CUDA线程可以读取全局内存中的数据，并且CUDA线程执行操作得到的结果可以写回全局内存。一旦内核完成执行，它写入全局内存的结果可以复制回主机，或者被GPU上的其他内核使用。

由于全局内存可被网格中的所有线程访问，因此必须注意避免线程之间的数据竞争。由于从主机启动的CUDA内核具有void返回类型，内核计算出的数值结果返回给主机的唯一方式是将这些结果写入全局内存。

一个说明全局内存使用的简单示例是下面的```vecAdd```内核，其中三个数组```A```、```B```和```C````位于全局内存中，并由这个向量加法内核进行访问。

```c++
__global__ void vecAdd(float* A, float* B, float* C, int vectorLength)
{
    int workIndex = threadIdx.x + blockIdx.x*blockDim.x;
    if(workIndex < vectorLength)
    {
        C[workIndex] = A[workIndex] + B[workIndex];
```

### 3.2. 共享内存

共享内存是线程块中所有线程都可访问的内存空间。它物理上位于每个SM上，并与L1缓存（统一数据缓存）使用相同的物理资源。共享内存中的数据在整个内核执行期间保持不变。共享内存可视为内核执行期间使用的用户管理的暂存器。
虽然与全局内存相比容量较小，但由于共享内存位于每个SM上，因此其带宽比访问全局内存更高，延迟更低。

由于共享内存可被线程块中的所有线程访问，因此必须注意避免同一线程块中线程之间的数据竞争。可以使用```__syncthreads()```函数实现同一线程块中线程之间的同步。此函数会阻塞线程块中的所有线程，直到所有线程都执行到对```__syncthreads()```的调用。

```c++
// assuming blockDim.x is 128
__global__ void example_syncthreads(int* input_data, int* output_data) {
    __shared__ int shared_data[128];
    // Every thread writes to a distinct element of 'shared_data':
    shared_data[threadIdx.x] = input_data[threadIdx.x];

    // All threads synchronize, guaranteeing all writes to 'shared_data' are ordered 
    // before any thread is unblocked from '__syncthreads()':
    __syncthreads();

    // A single thread safely reads 'shared_data':
    if (threadIdx.x == 0) {
        int sum = 0;
        for (int i = 0; i < blockDim.x; ++i) {
            sum += shared_data[i];
        }
        output_data[blockIdx.x] = sum;
    }
}
```

共享内存的大小取决于所使用的GPU架构。由于共享内存和L1缓存共享相同的物理空间，使用共享内存会减小内核可用的L1缓存大小。此外，如果内核不使用共享内存，整个物理空间将被L1缓存占用。
CUDA运行时API提供了按每个SM和每个线程块查询共享内存大小的函数，可使用```cudaGetDeviceProperties```函数并查看```cudaDeviceProp.sharedMemPerMultiprocessor```和```cudaDeviceProp.sharedMemPerBlock```设备属性。

CUDA运行时API提供了一个名为```cudaFuncSetCacheConfig```的函数，用于告知运行时是为共享内存分配更多空间，还是为L1缓存分配更多空间。该函数向运行时指定了一种偏好，但不保证会被采纳。运行时可根据可用资源和内核需求自主做出决策。

共享内存既可以静态分配，也可以动态分配。

#### 3.2.1 共享内存的静态分配

要静态分配共享内存，程序员必须在核函数内使用```__shared__```说明符声明一个变量。该变量将被分配到共享内存中，并在核函数执行期间保持存在。通过这种方式声明的共享内存大小必须在编译时指定。
例如，位于核函数体中的以下代码片段声明了一个包含1024个元素的```float```类型共享内存数组。

```c++
__shared__ float sharedArray[1024];
```

在此声明之后，线程块中的所有线程都将能够访问这个共享内存数组。必须注意避免同一线程块中线程之间的数据竞争，通常可以通过使用```__syncthreads()```来实现。

#### 3.2.2 共享内存的动态分配

要动态分配共享内存，程序员可以在三重尖括号表示法的内核启动中，将每个线程块所需的共享内存大小（以字节为单位）指定为第三个（可选）参数，如下所示：```functionName<<<grid, block, sharedMemoryBytes>>>()```。

然后，在核函数内部，程序员可以使用```extern __shared__```说明符来声明一个将在核函数启动时动态分配的变量。

```c++
extern __shared__ float sharedArray[];
```

一个需要注意的地方是，如果想要多个动态分配的共享内存数组，必须使用指针运算手动划分单个```extern __shared__```。例如，如果想要实现以下等效功能，

```c++
short array0[128];
float array1[64];
int   array2[256];
```

在动态分配的共享内存中，可以通过以下方式声明和初始化数组：

```c++
extern __shared__ float array[];

short* array0 = (short*)array;
float* array1 = (float*)&array0[128];
int*   array2 =   (int*)&array1[64];
```

请注意，指针需要与它们所指向的类型对齐，因此例如下面的代码无法运行，因为```array1```没有按4字节对齐

```c++
extern __shared__ float array[];
short* array0 = (short*)array;
float* array1 = (float*)&array0[127];
```

### 3.3 寄存器

寄存器位于SM上，具有线程本地作用域。寄存器的使用由编译器管理，在核函数执行期间，寄存器用于线程本地存储。可以使用GPU的```regsPerMultiprocessor```和```regsPerBlock```设备属性查询每个SM的寄存器数量以及每个线程块的寄存器数量。

NVCC允许开发者通过```-maxrregcount```选项来指定内核使用的最大寄存器数量。使用该选项减少内核可使用的寄存器数量，可能会使更多线程块同时在SM上调度，但也可能导致更多的寄存器溢出。

### 3.4 本地内存

本地内存是类似于寄存器的线程本地存储，由NVCC管理，但其物理位置位于全局内存空间中。“本地”这一标签指的是它的逻辑作用域，而非物理位置。本地内存在内核执行期间用于线程本地存储。编译器可能会将以下自动变量放入本地内存中：

+ 无法确定其索引为常量的数组，

+ 会占用过多寄存器空间的大型结构或数组，

+ 如果内核使用的寄存器数量超过可用数量，则任何变量都会发生寄存器溢出。

由于本地内存空间位于设备内存中，本地内存访问与全局内存访问具有相同的延迟和带宽，并且遵循合并全局内存访问中所述的相同内存合并要求。不过，本地内存的组织方式是让连续的32位字由连续的线程ID访问。
因此，只要一个线程束中的所有线程访问相同的相对地址（例如数组变量中的相同索引或结构变量中的相同成员），访问就会完全合并。

### 3.5. 常量内存

常量内存具有网格作用域，在应用程序的生命周期内均可访问。常量内存位于设备上，对内核而言是只读的。因此，它必须在主机端使用```__constant__```说明符进行声明和初始化，且要放在任何函数之外。

```__constant__``` 内存空间说明符声明的变量具有以下特性：

+ 驻留在常量内存空间中

+ 其生命周期与创建它的CUDA上下文相同

+ 每个设备有一个不同的对象

+ 可从网格内的所有线程以及通过运行时库（```cudaGetSymbolAddress()``` / ```cudaGetSymbolSize()``` / ```cudaMemcpyToSymbol()``` / ```cudaMemcpyFromSymbol()```）从主机进行访问。

常量内存的总量可以通过```totalConstMem```设备属性元素进行查询.

常量内存对于每个线程将以只读方式使用的少量数据很有用。与其他内存相比，常量内存容量较小，通常每个设备为64KB。

下面是一个声明和使用常量内存的示例代码片段：

```c++
// In your .cu file
__constant__ float coeffs[4];

__global__ void compute(float *out) {
    int idx = threadIdx.x;
    out[idx] = coeffs[0] * idx + coeffs[1];
}

// In your host code
float h_coeffs[4] = {1.0f, 2.0f, 3.0f, 4.0f};
cudaMemcpyToSymbol(coeffs, h_coeffs, sizeof(h_coeffs));
compute<<<1, 10>>>(device_out);
```

### 3.6 Caches

GPU设备具有多级缓存结构，包括L2和L1缓存。

L2缓存位于设备上，由所有SM共享。可以通过函数```cudaGetDeviceProperties```中的```l2CacheSize```设备属性元素查询L2缓存的大小。

如上文在共享内存中所述，L1缓存物理上位于每个SM上，并且与共享内存使用的是同一物理空间。如果内核未使用共享内存，那么整个物理空间将由L1缓存占用。

L2和L1缓存可通过一些函数进行控制，这些函数允许开发人员指定各种缓存行为。这些函数的详细信息可在配置L1/共享内存平衡、L2缓存控制和低级加载与存储函数中找到。

如果不使用这些提示，编译器和运行时将尽力高效地利用缓存。

### 3.7. 纹理与表面记忆

GPU可能具有专门的指令，用于从图像加载数据，以在3D渲染中用作纹理。CUDA通过纹理对象API和表面对象API公开了这些指令以及使用它们的机制。

本指南不再进一步讨论纹理内存和表面内存，因为在任何当前支持的NVIDIA GPU上，在CUDA中使用它们并没有优势。CUDA开发者完全可以忽略这些API。对于处理仍在使用这些API的现有代码库的开发者而言，仍可在旧版《CUDA C++编程指南》中找到这些API的解释。

### 3.9. 分布式共享内存

线程块集群在计算能力 9.0 中引入，并由 协作组提供支持，它使线程块集群中的线程能够访问该集群中所有参与线程块的共享内存。这种分区共享内存被称为 分布式共享内存，相应的地址空间被称为分布式共享内存地址空间。

属于线程块集群的线程可以在分布式地址空间中进行读取、写入或执行原子操作，无论该地址属于本地线程块还是远程线程块。无论内核是否使用分布式共享内存，共享内存大小规格（静态或动态）仍然是每个线程块的规格。

分布式共享内存的大小就是每个集群的线程块数量乘以每个线程块的共享内存大小。


访问分布式共享内存中的数据需要所有线程块都存在。用户可以通过来自 ```cluster_group```类的```cluster.sync()```来确保所有线程块已开始执行。用户还需要确保所有分布式共享内存操作都在线程块退出之前完成，
例如，如果某个远程线程块尝试读取特定线程块的共享内存，程序需要确保该远程线程块对共享内存的读取完成后，该特定线程块才能退出。

让我们来看一个简单的直方图计算，以及如何使用线程块集群在GPU上对其进行优化。计算直方图的一种标准方法是在每个线程块的共享内存中执行计算，然后执行全局内存原子操作。这种方法的一个局限性在于共享内存的容量。

一旦直方图的分箱无法放入共享内存，用户就需要直接计算直方图，从而在全局内存中进行原子操作。借助分布式共享内存，CUDA提供了一个中间步骤，根据直方图分箱的大小，可以在共享内存、分布式共享内存或直接在全局内存中计算直方图。

下面的CUDA内核示例展示了如何根据直方图分箱的数量，在共享内存或分布式共享内存中计算直方图:

```c++
#include <cooperative_groups.h>

// Distributed Shared memory histogram kernel
__global__ void clusterHist_kernel(int *bins, const int nbins, const int bins_per_block, const int *__restrict__ input,
                                   size_t array_size)
{
  extern __shared__ int smem[];
  namespace cg = cooperative_groups;
  int tid = cg::this_grid().thread_rank();

  // Cluster initialization, size and calculating local bin offsets.
  cg::cluster_group cluster = cg::this_cluster();
  unsigned int clusterBlockRank = cluster.block_rank();
  int cluster_size = cluster.dim_blocks().x;

  for (int i = threadIdx.x; i < bins_per_block; i += blockDim.x)
  {
    smem[i] = 0; //Initialize shared memory histogram to zeros
  }

  // cluster synchronization ensures that shared memory is initialized to zero in
  // all thread blocks in the cluster. It also ensures that all thread blocks
  // have started executing and they exist concurrently.
  cluster.sync();

  for (int i = tid; i < array_size; i += blockDim.x * gridDim.x)
  {
    int ldata = input[i];

    //Find the right histogram bin.
    int binid = ldata;
    if (ldata < 0)
      binid = 0;
    else if (ldata >= nbins)
      binid = nbins - 1;

    //Find destination block rank and offset for computing
    //distributed shared memory histogram
    int dst_block_rank = (int)(binid / bins_per_block);
    int dst_offset = binid % bins_per_block;

    //Pointer to target block shared memory
    int *dst_smem = cluster.map_shared_rank(smem, dst_block_rank);

    //Perform atomic update of the histogram bin
    atomicAdd(dst_smem + dst_offset, 1);
  }

  // cluster synchronization is required to ensure all distributed shared
  // memory operations are completed and no thread block exits while
  // other thread blocks are still accessing distributed shared memory
  cluster.sync();

  // Perform global memory histogram, using the local distributed memory histogram
  int *lbins = bins + cluster.block_rank() * bins_per_block;
  for (int i = threadIdx.x; i < bins_per_block; i += blockDim.x)
  {
    atomicAdd(&lbins[i], smem[i]);
  }
}
```

上述内核可以在运行时启动，其集群大小取决于所需的分布式共享内存量。如果直方图足够小，可以放入单个块的共享内存中，用户可以以集群大小1启动该内核。下面的代码片段展示了如何根据共享内存需求动态启动集群内核。

```c++
// Launch via extensible launch
{
  cudaLaunchConfig_t config = {0};
  config.gridDim = array_size / threads_per_block;
  config.blockDim = threads_per_block;

  // cluster_size depends on the histogram size.
  // ( cluster_size == 1 ) implies no distributed shared memory, just thread block local shared memory
  int cluster_size = 2; // size 2 is an example here
  int nbins_per_block = nbins / cluster_size;

  //dynamic shared memory size is per block.
  //Distributed shared memory size =  cluster_size * nbins_per_block * sizeof(int)
  config.dynamicSmemBytes = nbins_per_block * sizeof(int);

  CUDA_CHECK(::cudaFuncSetAttribute((void *)clusterHist_kernel, cudaFuncAttributeMaxDynamicSharedMemorySize, config.dynamicSmemBytes));

  cudaLaunchAttribute attribute[1];
  attribute[0].id = cudaLaunchAttributeClusterDimension;
  attribute[0].val.clusterDim.x = cluster_size;
  attribute[0].val.clusterDim.y = 1;
  attribute[0].val.clusterDim.z = 1;

  config.numAttrs = 1;
  config.attrs = attribute;

  cudaLaunchKernelEx(&config, clusterHist_kernel, bins, nbins, nbins_per_block, input, array_size);
}
```

## 4. 内存性能

确保适当的内存使用是在CUDA核函数中实现高性能的关键。本节讨论了在CUDA核函数中实现高内存吞吐量的一些一般原则和示例。

### 4.1. 合并全局内存访问

全局内存通过32字节的内存事务进行访问。当一个CUDA线程从全局内存中请求一个数据字时，相关的线程束会将该线程束中所有线程的内存请求合并为满足请求所需的内存事务数量，这取决于每个线程访问的数据字大小以及各线程间内存地址的分布情况。

例如，如果一个线程请求一个4字节的数据字，线程束向全局内存生成的实际内存事务总大小将为32字节。为了最有效地利用内存系统，线程束应使用单次内存事务中获取的所有内存。

也就是说，如果一个线程从全局内存中请求一个4字节的数据字，而事务大小为32字节，那么若该线程束中的其他线程能够使用该32字节请求中的其他4字节数据字，将能实现内存系统的最高效利用。

举一个简单的例子，如果线程束中的连续线程请求内存中连续的4字节字，那么该线程束总共会请求128字节的内存，而所需的这128字节将通过4次32字节的内存事务来获取。这实现了内存系统100%的利用率。

也就是说，线程束利用了100%的内存流量。下图展示了这种完全合并内存访问的示例。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/perfect_coalescing_32byte_segments.png)

相反，最糟糕的病态情况是当连续线程访问内存中彼此相距32字节或更远的数据元素时。在这种情况下，线程束将被迫为每个线程发出32字节的内存事务，内存流量的总字节数将是32字节乘以32线程/线程束=1024字节。

然而，实际使用的内存量仅为128字节（线程束中每个线程4字节），因此内存利用率仅为128/1024=12.5%。这是对内存系统的一种非常低效的使用。下图展示了这种非合并内存访问的示例。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/no_coalescing_32byte_segments.png)


实现合并内存访问最直接的方法是让连续的线程访问内存中的连续元素。


例如，对于使用一维线程块启动的内核，下面的VecAdd内核将实现合并内存访问。注意线程```workIndex```如何访问这三个数组，以及连续的线程（由```workIndex```的连续值表示）如何访问数组中的连续元素。

```c++
__global__ void vecAdd(float* A, float* B, float* C, int vectorLength)
{
    int workIndex = threadIdx.x + blockIdx.x*blockDim.x;
    if(workIndex < vectorLength)
    {
        C[workIndex] = A[workIndex] + B[workIndex];
```

实现合并内存访问并不要求连续的线程访问连续的内存元素，这仅仅是实现合并的典型方式。只要 warp 中的所有线程以某种线性或置换的方式访问来自相同 32 字节内存段的元素，就会发生合并内存访问。

换句话说，实现合并内存访问的最佳方法是最大化已用字节与传输字节的比率。

#### 4.1.1  使用全局内存的矩阵转置示例

举一个简单的例子，考虑一个非原地矩阵转置核函数，它将一个大小为N×N的32位浮点方阵从矩阵```a```转置到矩阵```c```。

因此每个二维线程块将处理矩阵中一个32×32的子块。每个线程处理矩阵的一个唯一元素，因此不需要线程的显式同步。下图展示了这种矩阵转置操作。核函数源代码紧随该图之后。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/global_transpose.png)

```
每个矩阵顶部和左侧的标签是二维线程块索引，也可以视为瓦片索引，其中每个小方块表示将由二维线程块操作的矩阵瓦片。
在这个示例中，瓦片大小为32×32元素，因此每个小方块都代表矩阵的一个32×32瓦片。绿色阴影方块显示了转置操作前后示例瓦片的位置。
```

```c++
/* macro to index a 1D memory array with 2D indices in row-major order */
/* ld is the leading dimension, i.e. the number of columns in the matrix     */

#define INDX( row, col, ld ) ( ( (row) * (ld) ) + (col) )

/* CUDA kernel for naive matrix transpose */

__global__ void naive_cuda_transpose(int m, float *a, float *c )
{
    int myCol = blockDim.x * blockIdx.x + threadIdx.x;
    int myRow = blockDim.y * blockIdx.y + threadIdx.y;

    if( myRow < m && myCol < m )
    {
        c[INDX( myCol, myRow, m )] = a[INDX( myRow, myCol, m )];
    } /* end if */
    return;
} /* end naive_cuda_transpose */
```

然而，```c```的写入操作并未合并，因为```threadIdx.x```的连续值（再次查看```myCol```）向```c```写入的元素彼此间隔```ld```（领先维度）个元素。

这一点可以从以下情况看出：现在```myCol```是```INDX```宏的第一个参数，当```INDX```的第一个参数递增1时，内存位置会按```ld```发生变化。当```ld```大于32时（只要矩阵大小大于32，就会出现这种情况），
这就等同于上面图中中所示的极端情况。

为了缓解这些未合并的写入，可以采用共享内存，这将在下一节中进行描述。

### 4.2. 共享内存访问模式

共享内存有32个banks，其组织方式为连续的32位字映射到连续的存储体。每个存储体的带宽为每时钟周期32位。

当同一线程束中的多个线程尝试访问同一存储体中的不同元素时，就会发生banks冲突。在这种情况下，对该存储体中数据的访问将被序列化，直到所有请求该存储体数据的线程都获取到数据为止。这种访问的序列化会导致性能损失。

此场景的两个例外情况发生在同一 warp 中的多个线程访问（读取或写入）同一个共享内存位置时。对于读取访问，该数据会广播到请求的线程。对于写入访问，每个共享内存地址仅由其中一个线程写入（具体哪个线程执行写入操作是未定义的）。

下图展示了一些跨步访问的示例。存储体中的红色框表示共享内存中的一个唯一位置。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/examples-of-strided-shared-memory-accesses.png)

下图展示了一些涉及广播机制的内存读取访问示例。存储体内部的红色方框表示共享内存中的一个独特位置。如果多个箭头指向同一位置，则数据会广播到所有请求它的线程。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/examples-of-irregular-shared-memory-accesses.png)

左图: 通过随机置换实现无冲突访问。

中间：无冲突访问，因为线程3、4、6、7和9访问存储体5中的同一个字

右图：无冲突广播访问（线程访问存储体中的同一个字）

#### 4.2.1. 使用共享内存的矩阵转置示例

```c++
/* definitions of thread block size in X and Y directions */

#define THREADS_PER_BLOCK_X 32
#define THREADS_PER_BLOCK_Y 32

/* macro to index a 1D memory array with 2D indices in row-major order */
/* ld is the leading dimension, i.e. the number of columns in the matrix     */

#define INDX( row, col, ld ) ( ( (row) * (ld) ) + (col) )

/* CUDA kernel for shared memory matrix transpose */

__global__ void smem_cuda_transpose(int m, float *a, float *c )
{

    /* declare a statically allocated shared memory array */

    __shared__ float smemArray[THREADS_PER_BLOCK_X][THREADS_PER_BLOCK_Y];

    /* determine my row tile and column tile index */

    const int tileCol = blockDim.x * blockIdx.x;
    const int tileRow = blockDim.y * blockIdx.y;

    /* read from global memory into shared memory array */
    smemArray[threadIdx.x][threadIdx.y] = a[INDX( tileRow + threadIdx.y, tileCol + threadIdx.x, m )];

    /* synchronize the threads in the thread block */
    __syncthreads();

    /* write the result from shared memory to global memory */
    c[INDX( tileCol + threadIdx.y, tileRow + threadIdx.x, m )] = smemArray[threadIdx.y][threadIdx.x];
    return;

} /* end smem_cuda_transpose */
```

本示例中展示的基本性能优化是确保在访问全局内存时，内存访问能够正确合并。在执行复制操作之前，每个线程会计算其```tileRow```和```tileCol```索引。
这些是将要操作的特定瓦片的索引，且这些瓦片索引基于正在执行的线程块。同一线程块中的每个线程都具有相同的```tileRow```和```tileCol```值，因此可以将其视为该特定线程块将要操作的瓦片的起始位置。

然后，内核会让每个线程块通过以下语句将矩阵的一个32×32的瓦片从全局内存复制到共享内存。由于一个线程束的大小为32个线程，此复制操作将由32个线程束执行，且线程束之间没有确定的执行顺序。

```c++
smemArray[threadIdx.x][threadIdx.y] = a[INDX( tileRow + threadIdx.y, tileCol + threadIdx.x, m )];
```

请注意，由于```threadIdx.x```出现在```INDX```的第二个参数中，连续的线程会访问内存中的连续元素，因此对a的读取是完全合并的。

内核中的下一步是调用```__syncthreads()```函数。这确保了线程块中的所有线程在继续执行之前都已完成先前代码的执行，从而确保在下一步之前，将a写入共享内存的操作已完成。

这一点至关重要，因为下一步将涉及线程从共享内存中读取数据。如果没有```__syncthreads()```调用，就无法保证线程块中的所有线程束在某些线程束进一步执行代码之前，都已完成将a读取到共享内存的操作。

在核函数的这一步，对于每个线程块，```smemArray``` 包含一个 32×32 的矩阵瓦片，其排列顺序与原始矩阵相同。为确保瓦片中的元素正确转置，在读取 ```smemArray``` 时，```threadIdx.x``` 和 ```threadIdx.y``` 会被交换。

为确保整个瓦片在 ```c``` 中放置在正确位置，在写入 ```c``` 时，```tileRow``` 和 ```tileCol``` 索引也会被交换。为确保正确的合并访问，```threadIdx.x``` 被用作 ```INDX``` 的第二个参数，如下列语句所示。

```c++
c[INDX( tileCol + threadIdx.y, tileRow + threadIdx.x, m )] = smemArray[threadIdx.y][threadIdx.x];
```

这个内核展示了共享内存的两种常见用途：

+ 共享内存用于暂存来自全局内存的数据，以确保对全局内存的读写操作都能正确合并。

+ 共享内存用于允许同一线程块中的线程彼此共享数据。

#### 4.2.2. 共享内存banks冲突

在第2.2.4.2节中，描述了共享内存的banks结构。在之前的矩阵转置示例中，实现了对全局内存的正确合并内存访问，但没有考虑是否存在共享内存banks冲突。考虑以下二维共享内存声明：

```c++
__shared__ float smemArray[32][32];
```

由于一个线程束包含32个线程，同一线程束中的每个线程的```threadIdx.y```值是固定的，且满足```0 <= threadIdx.x < 32```。

下图的左面板展示了在一个线程束中的线程访问smemArray的一列数据时的情况。线程束0正在访问从```smemArray[0][0]```到```smemArray[31][0]```的内存位置。

在C++多维数组的排序方式中，最后一个索引的变化最快，因此线程束0中的连续线程访问的内存位置相隔32个元素。如图所示，颜色代表不同的存储体，线程束0对整列数据的这种访问方式会导致32路存储体冲突。


下图的右面板展示了当一个warp中的线程跨```smemArray```的一行访问数据时的情况。Warp 0正在访问从```smemArray[0][0]```到```smemArray[0][31]```的内存位置。在这种情况下，warp 0中的连续线程访问的是相邻的内存位置。如图所示，颜色代表存储体，warp 0对整行的这种访问不会导致存储体冲突。理想情况是，一个warp中的每个线程访问具有不同颜色的共享内存位置。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/bank-conflicts-shared-mem.png)

回到2.2.4.2.1节中的示例，可以通过检查共享内存的使用情况来确定是否存在存储体冲突。共享内存的首次使用是将全局内存中的数据存储到共享内存时：

```c++
smemArray[threadIdx.x][threadIdx.y] = a[INDX( tileRow + threadIdx.y, tileCol + threadIdx.x, m )];
```

由于C++数组以行优先顺序存储，同一线程束中的连续线程（由```threadIdx.x```的连续值表示）访问```smemArray```时的步长为32个元素，因为```threadIdx.x```是该数组的第一个索引。这会导致32路存储体冲突，如下图的左面板所示。

共享内存的第二种用法是将共享内存中的数据写回全局内存时：

```c++
c[INDX( tileCol + threadIdx.y, tileRow + threadIdx.x, m )] = smemArray[threadIdx.y][threadIdx.x];
```

在这种情况下，由于```threadIdx.x```是```smemArray```数组的第二个索引，同一线程束中的连续线程将以1个元素的步长访问```smemArray```。这不会导致存储体冲突，上图的右侧面板对此进行了说明。

如上图节所示，矩阵转置核函数有一次共享内存访问不存在bank冲突，还有一次访问存在32路bank冲突。避免bank冲突的一种常见解决方法是通过将数组的列维度加1来对共享内存进行填充，具体如下：

```c++
__shared__ float smemArray[THREADS_PER_BLOCK_X][THREADS_PER_BLOCK_Y+1];
```

对```smemArray```声明的这一微小调整将消除存储体冲突。为了说明这一点，不妨看看下图，其中共享内存数组被声明为32×33的大小。可以发现，无论同一线程束中的线程是沿整个列还是整个行访问共享内存数组，
存储体冲突都已消除，也就是说，同一线程束中的线程访问的是不同颜色的位置。

![](https://docs.nvidia.com/cuda/cuda-programming-guide/_images/no-bank-conflicts-shared-mem.png)

## 5. 原子操作

高性能的CUDA内核依赖于尽可能多地体现算法并行性。GPU内核执行的异步特性要求线程尽可能独立地运行。线程并非总能完全独立，正如我们在共享内存中所看到的，存在一种机制，使得同一线程块中的线程能够交换数据并进行同步。

在整个网格层面，没有这样的机制来同步网格中的所有线程。不过，有一种机制可以通过使用原子函数来提供对全局内存位置的同步访问。

原子函数允许线程对全局内存位置获取锁，并对该位置执行读-修改-写操作。在持有锁期间，其他任何线程都无法访问同一位置。CUDA 提供的原子操作与 C++ 标准库中的原子操作行为相同，即```cuda::std::atomic```和```cuda::std::atomic_ref```。

CUDA 还提供了扩展的 C++ 原子操```作cuda::atomic```和```cuda::atomic_ref```，允许用户指定原子操作的线程作用域。

以下是使用```cuda::atomic_ref```执行设备级原子加法的示例，其中```array```是一个浮点数组，```result```是指向全局内存中某个位置的浮点指针，该位置将存储数组的总和。

```c++
__global__ void sumReduction(int n, float *array, float *result) {
   ...
   tid = threadIdx.x + blockIdx.x * blockDim.x;

   cuda::atomic_ref<float, cuda::thread_scope_device> result_ref(result);
   result_ref.fetch_add(array[tid]);
   ...
}
```

## 6. 合作组

协作组是CUDA C++中提供的一种软件工具，它允许应用程序定义线程组，这些线程组可以相互同步，即便该线程组跨越多个线程块、单个GPU上的多个网格，甚至是多个GPU。
总体而言，CUDA编程模型允许线程块或线程块集群内的线程高效同步，但不提供用于指定小于线程块或集群的线程组的机制。同样，CUDA编程模型也不提供支持线程块间同步的机制或保证。

协作组通过软件提供这两种功能。协作组允许应用程序创建跨越线程块和集群边界的线程组，不过这样做存在一些语义限制和性能影响，这些在涵盖协作组的功能部分中有详细描述。

## 7. 内核启动和占用率

当一个CUDA内核启动时，CUDA线程会根据内核启动时指定的执行配置被分组为线程块和网格。内核启动后，调度器会将线程块分配给SM（流式多处理器）。

应用程序无法控制或查询哪些线程块被调度到哪些SM上执行，调度器也不保证执行顺序，因此程序不能依赖特定的调度顺序或方案来确保正确执行。

一个SM上可调度的块数量取决于特定线程块所需的硬件资源以及该SM上可用的硬件资源。当内核首次启动时，调度器开始将线程块分配给各个SM。只要SM上有足够的硬件资源未被其他线程块占用，
调度器就会继续将线程块分配给SM。

如果在某个时刻没有SM有能力接收另一个线程块，调度器将等待，直到这些SM完成之前分配的线程块。一旦完成，SM就可以接收更多任务，调度器会将线程块分配给它们。这个过程会持续进行，直到所有线程块都被调度并执行完毕。

```cudaGetDeviceProperties```函数允许应用程序通过设备属性查询每个SM的限制。请注意，每个SM和每个线程块都有限制。

+ maxBlocksPerMultiProcessor：每个SM的最大驻留块数。

+ sharedMemPerMultiprocessor：每个SM可用的共享内存量（以字节为单位）。

+ regsPerMultiprocessor：每个SM可用的32位寄存器数量。

+ maxThreadsPerMultiProcessor：每个SM的最大驻留线程数。

+ sharedMemPerBlock：线程块可分配的最大共享内存量（以字节为单位）

+ regsPerBlock：一个线程块可分配的32位寄存器的最大数量

+ maxThreadsPerBlock：每个线程块的最大线程数

CUDA内核的占用率是活跃线程束数量与流式多处理器（SM）支持的最大活跃线程束数量之比。通常，尽可能提高占用率是一种良好的做法，因为这可以隐藏延迟并提升性能。

要计算占用率，需要知道刚刚描述过的SM的资源限制，还需要知道相关CUDA内核所需的资源。要确定每个内核的资源使用情况，在程序编译期间，可以使用nvcc的--resource-usage选项，该选项会显示内核所需的寄存器数量和共享内存。

举个例子，考虑一个计算能力为10.0的设备，其设备属性在表2中列出。

表2 SM资源示例
| 资源 | 值 |
|------|-----|
| maxBlocksPerMultiProcessor | 32 |
| sharedMemPerMultiprocessor | 233472 |
| regsPerMultiprocessor | 65536 |
| maxThreadsPerMultiProcessor | 2048 |
| sharedMemPerBlock | 49152 |
| regsPerBlock | 65536 |
| maxThreadsPerBlock | 1024 |

如果一个内核以```testKernel<<<512, 768>>>()```的方式启动，即每个线程块有768个线程，那么每个SM一次只能执行2个线程块。由于```maxThreadsPerMultiProcessor```为2048，调度程序每个SM最多只能分配2个线程块。因此，占用率为（768×2）/2048，即75%。

如果内核以```testKernel<<<512, 32>>>()```启动，即每个块32个线程，那么每个SM不会遇到```maxThreadsPerMultiProcessor```的限制，但由于```maxBlocksPerMultiProcessor```为32，调度程序只能为每个SM分配32个线程块。

由于每个块中的线程数为32，驻留在SM上的总线程数将是32个块乘以每个块32个线程，即总共1024个线程。由于计算能力10.0的SM每个SM的最大驻留线程数为2048，因此在这种情况下，占用率为1024/2048，即50%。

同样的分析也适用于共享内存。例如，如果一个内核使用100KB的共享内存，调度器只能为每个SM分配2个线程块，因为该SM上的第三个线程块需要额外的100KB共享内存，总计达到300KB，这超过了每个SM可用的233472字节。

每个块的线程数和每个块的共享内存使用量由程序员明确控制，并且可以进行调整以达到理想的占用率。程序员对寄存器使用的控制有限，因为编译器和运行时会尝试优化寄存器的使用。

不过，程序员可以通过```nvcc```的```--maxrregcount```选项指定每个线程块的最大寄存器数量。如果内核需要的寄存器数量超过这个指定值，内核很可能会溢出到本地内存，这将改变内核的性能特征。在某些情况下，即使发生溢出，限制寄存器数量也能允许调度更多的线程块，进而提高占用率，并可能带来整体性能的提升。
